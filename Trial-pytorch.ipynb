{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33bfba3-f84c-43db-bad5-6ed057b7ab0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e3b275-a3c1-4e3a-a51a-3003d5833390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from random import randint\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch \n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636779",
   "metadata": {},
   "source": [
    "## Establishing folder structure for dataset \n",
    "data_split -> sub -> audio_material -> type_of_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f32d7b4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_ext = \"*.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d1bce8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dir_pth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_pth, file_ext))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_pth' is not defined"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(dir_pth, file_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983b4047",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_segmentation(fpath : str):\n",
    "  fname = (fpath.split(\"/\")[-1])\n",
    "  file_seg = (fpath.split(\"/\")[-1]).split(\"_-_\")[0]\n",
    "  print(fname)\n",
    "\n",
    "  # creating sub-dirs : train, val and test\n",
    "  for seg in [\"train\", \"val\", \"test\"]:\n",
    "    sub_dir = os.path.join(dir_pth, seg)\n",
    "    if not os.path.exists(sub_dir):\n",
    "      os.makedirs(sub_dir)\n",
    "\n",
    "  # moving file to desired segment folder\n",
    "  src_file = fpath\n",
    "  dest_file = os.path.join(dir_pth, file_seg, fname)\n",
    "  shutil.move(src_file, dest_file)\n",
    "\n",
    "  # Check if the file has been moved\n",
    "  if os.path.exists(dest_file):\n",
    "    print(f\"File has been moved to : {dest_file}\")\n",
    "  else:\n",
    "    print(\"File move operation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3a66f9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m      2\u001b[0m   data_segmentation(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "for f in file_list:\n",
    "  data_segmentation(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a5e8a-f8cc-4335-95b2-6e82d300004a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261a9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/klvijeth/Documents/ML-project/toy_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d55e5a8-4b6c-416c-b181-b5c1d463b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eeg_file_path = '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_eeg.npy'\n",
    "test_mel_file_path = '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_mel.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d157a7-ecf3-4536-9608-02da2fd756aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.unfold(0, self.frame_length, self.hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1c4406-36ec-415d-a2f4-9dfa859d86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG: \n"
     ]
    }
   ],
   "source": [
    "## test sliding window\n",
    "try_eeg = torch.from_numpy(np.load(test_eeg_file_path))\n",
    "try_mel= torch.from_numpy(np.load(test_mel_file_path))\n",
    "print(\"EEG: \",) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c69902-092b-4827-8817-32138641c48d",
   "metadata": {},
   "source": [
    "### Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a679f02-0e6c-4cd6-843d-ad827a4a7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(data.Dataset):\n",
    "    def __init__(self, files, input_length, channels, task, g_con = True) -> None:\n",
    "        super().__init__()\n",
    "        self.input_length = input_length\n",
    "        self.files = self.group_recordings(files)\n",
    "        self.channels = channels\n",
    "        self.task = task\n",
    "        self.g_con = g_con\n",
    "\n",
    "    def group_recordings(self, files):\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "        return new_files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, recording_index):\n",
    "        if self.task !=\"test\":\n",
    "            framed_data = []\n",
    "            for idx, feature in enumerate(self.files[recording_index]):\n",
    "                data = np.load(feature)\n",
    "                if idx == 0:\n",
    "                    start_idx = randint(0, len(data) - self.input_length)\n",
    "                    \n",
    "                framed_data += [data[start_idx:start_idx + self.input_length]]\n",
    "            if self.g_con == True:\n",
    "                sub_id = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "                sub_id = int(sub_id) - 1\n",
    "            else:\n",
    "                sub_id = torch.FloatTensor([0])\n",
    "            return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1])\n",
    "        else:\n",
    "            for idx, feature in enumerate(self.files[recording_index]):\n",
    "                data = np.load(feature)\n",
    "                nsegment = data.shape[0] // self.input_length\n",
    "                data = data[:int(nsegment * self.input_length)]\n",
    "                segment_data = [torch.FloatTensor(data[i:i+self.input_length]).unsqueeze(0) for i in range(0, data.shape[0], self.input_length)]\n",
    "                segment_data = torch.cat(segment_data)\n",
    "                framed_data += [segment_data]\n",
    "            \n",
    "            if self.g_con == True:\n",
    "                sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "                sub_idx = int(sub_idx) - 1    \n",
    "    \n",
    "            else:\n",
    "                sub_idx = torch.FloatTensor([0])\n",
    "            return framed_data[0], framed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ede82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5578e769-9706-49de-bdf4-36cb27064b54",
   "metadata": {},
   "source": [
    "### Lightning DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0821087a-694e-4ad4-8aa7-dcbd135c7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(y_true, y_pred, axis=1):\n",
    "\n",
    "    y_true_mean = torch.mean(y_true, dim=axis, keepdim=True)\n",
    "    y_pred_mean = torch.mean(y_pred, dim=axis, keepdim=True)\n",
    "\n",
    "    # Compute the numerator and denominator of the pearson correlation.\n",
    "    numerator = torch.sum((y_true - y_true_mean) * (y_pred - y_pred_mean),\n",
    "        dim=axis,\n",
    "        keepdim=False)\n",
    "\n",
    "    std_true = torch.sum((y_true - y_true_mean)**2, dim=axis, keepdim=False)\n",
    "    std_pred = torch.sum((y_pred - y_pred_mean)**2, dim=axis, keepdim=False)\n",
    "    denominator = torch.sqrt(std_true * std_pred)\n",
    "    \n",
    "    pearsonR = torch.div(numerator, denominator + 1e-6)\n",
    "\n",
    "    assert torch.all(torch.lt(pearsonR, 1)) and torch.all(torch.gt(pearsonR, -1)), \"Loss contains values outside the range of -1 to 1\"\n",
    "\n",
    "    return pearsonR\n",
    "\n",
    "\n",
    "def pearson_loss(y_true, y_pred, axis=1):\n",
    "    return -pearson_correlation(y_true, y_pred, axis=axis)\n",
    "\n",
    "def pearson_metric(y_true, y_pred, axis=1):\n",
    "    return pearson_correlation(y_true, y_pred, axis=axis)\n",
    "    \n",
    "def l1_loss(y_true, y_pred, axis=1):\n",
    "    l1_dist = torch.abs(y_true - y_pred)\n",
    "    l1_loss = torch.mean(l1_dist, axis = axis, keepdim=False)\n",
    "    return l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b86ac5cf-5ec8-4359-b8e6-cb0f9115719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pdb\n",
    "from random import randint\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    \"\"\"Generate data for the regression task.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        files,\n",
    "        input_length,\n",
    "        channels,\n",
    "        task,\n",
    "        g_con = True\n",
    "    ):\n",
    "\n",
    "        self.input_length = input_length\n",
    "        self.files = self.group_recordings(files)\n",
    "        self.channels = channels\n",
    "        self.task = task\n",
    "        self.g_con = g_con\n",
    "\n",
    "    def group_recordings(self, files):\n",
    " \n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "\n",
    "        return new_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, recording_index):\n",
    "        \n",
    "        # 1. For within subject, return eeg, envelope and subject ID\n",
    "        # 2. For held-out subject, return eeg, envelope\n",
    "\n",
    "        if self.task == \"train\":\n",
    "            x, y = self.__train_data__(recording_index)\n",
    "\n",
    "        else:\n",
    "            x, y = self.__test_data__(recording_index)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __train_data__(self, recording_index):\n",
    "\n",
    "        framed_data = []\n",
    "\n",
    "        for idx, feature in enumerate(self.files[recording_index]):\n",
    "            data = np.load(feature)\n",
    "\n",
    "            if idx == 0: \n",
    "                start_idx= randint(0,len(data)- self.input_length)\n",
    "\n",
    "            framed_data += [data[start_idx:start_idx + self.input_length]]\n",
    "\n",
    "        if self.g_con == True:\n",
    "            sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "            sub_idx = int(sub_idx) - 1 \n",
    "    \n",
    "        else:\n",
    "            sub_idx = torch.FloatTensor([0])\n",
    "    \n",
    "            # return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1]), sub_idx\n",
    "        \n",
    "            \n",
    "        return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1])\n",
    "\n",
    "    def __test_data__(self, recording_index):\n",
    "        \"\"\"\n",
    "        return: list of segments [[eeg, envelope] ...] depending on self.input_length \n",
    "                e.g.,for 10 second-long input signal and input_length==5, return [[5, 5], [5, 5]]\n",
    "        \n",
    "        \"\"\"\n",
    "        framed_data = []\n",
    "\n",
    "        for idx, feature in enumerate(self.files[recording_index]):\n",
    "            data = np.load(feature)\n",
    "            nsegment = data.shape[0] // self.input_length\n",
    "            data = data[:int(nsegment * self.input_length)]\n",
    "            segment_data = [torch.FloatTensor(data[i:i+self.input_length]).unsqueeze(0) for i in range(0, data.shape[0], self.input_length)]\n",
    "            segment_data = torch.cat(segment_data)\n",
    "            framed_data += [segment_data]\n",
    "            \n",
    "        if self.g_con == True:\n",
    "            sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "            sub_idx = int(sub_idx) - 1    \n",
    "\n",
    "        else:\n",
    "            sub_idx = torch.FloatTensor([0])\n",
    "\n",
    "        return framed_data[0], framed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06c9caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"eeg\"] + [\"mel\"]\n",
    "path=\"/Users/klvijeth/Documents/ML-project/toy_split/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4418aa39-2086-4381-bade-2fca02eae335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourModel(\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (conv): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YourModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "        self.conv = nn.Conv1d(64, 128, kernel_size = 7, padding=3)\n",
    "\n",
    "    def forward(self, dec_input):\n",
    "        dec_output = self.conv(dec_input.transpose(1,2))\n",
    "        dec_output = dec_output.transpose(1,2)\n",
    "        #print(dec_output.size())\n",
    "        dec_output=self.fc(dec_output)\n",
    "        return dec_output\n",
    "\n",
    "# Assuming nb_channels, nb_filters, and integration_window are defined\n",
    "nb_channels = 64\n",
    "nb_filters = 1\n",
    "integration_window = 32\n",
    "\n",
    "# Create an instance of the model\n",
    "model = YourModel()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3362d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"/Users/klvijeth/Documents/ML-project/toy_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "602abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.0005,\n",
    "                                betas=(0.9, 0.98),\n",
    "                                eps=1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a43b078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RegressionDataset object at 0x15e86b7d0>\n"
     ]
    }
   ],
   "source": [
    "train_files = [x for x in glob.glob(os.path.join(folder_path+\"/train/\",\"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "train_set= RegressionDataset(train_files, 640, 64, 'train', False)\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d341f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size = 1,\n",
    "            num_workers = 0,\n",
    "            sampler = None,\n",
    "            drop_last=True,\n",
    "            shuffle=True)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5a1dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = [x for x in glob.glob(os.path.join(folder_path+\"/val/\", \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "val_set = RegressionDataset(val_files, 640, 64, 'val', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "045a6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size = 1,\n",
    "        num_workers = 0,\n",
    "        sampler = None,\n",
    "        drop_last=True,\n",
    "        shuffle=False)\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f3e5adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [x for x in glob.glob(os.path.join(folder_path+\"/test/\", \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "test_set = RegressionDataset(test_files, 640, 64, 'test', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb12617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size = 1,\n",
    "        num_workers = 0,\n",
    "        sampler = None,\n",
    "        drop_last=True,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f753055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "#writer = get_writer(result_folder, experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "798d95dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(f\"cuda:{args.gpu}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4fee88fb-97ad-4e54-b459-14e840de3be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourModel(\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (conv): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "Epoch 1\n",
      "|-Train-|0: 0.341\n",
      "|-Validation-|0: -0.006 0.006\n",
      "|-Test-|0: -0.000 0.000\n",
      "Epoch 2\n",
      "|-Train-|1: 0.171\n",
      "|-Validation-|1: -0.006 0.006\n",
      "|-Test-|1: -0.004 0.004\n",
      "Epoch 3\n",
      "|-Train-|2: 0.216\n",
      "|-Validation-|2: -0.006 0.006\n",
      "|-Test-|2: -0.003 0.003\n",
      "Epoch 4\n",
      "|-Train-|3: 0.151\n",
      "|-Validation-|3: -0.007 0.007\n",
      "|-Test-|3: -0.001 0.001\n",
      "Epoch 5\n",
      "|-Train-|4: 0.201\n",
      "|-Validation-|4: -0.009 0.009\n",
      "|-Test-|4: -0.001 0.001\n",
      "Epoch 6\n",
      "|-Train-|5: 0.213\n",
      "|-Validation-|5: -0.008 0.008\n",
      "|-Test-|5: -0.001 0.001\n",
      "Epoch 7\n",
      "|-Train-|6: 0.196\n",
      "|-Validation-|6: -0.007 0.007\n",
      "|-Test-|6: -0.000 0.000\n",
      "Epoch 8\n",
      "|-Train-|7: 0.158\n",
      "|-Validation-|7: -0.007 0.007\n",
      "|-Test-|7: 0.001 -0.001\n",
      "Epoch 9\n",
      "|-Train-|8: 0.156\n",
      "|-Validation-|8: -0.008 0.008\n",
      "|-Test-|8: 0.001 -0.001\n",
      "Epoch 10\n",
      "|-Train-|9: 0.191\n",
      "|-Validation-|9: -0.008 0.008\n",
      "|-Test-|9: 0.001 -0.001\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch\",epoch+1)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #sub_id = sub_id.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        l_p = pearson_loss(outputs, labels) \n",
    "        l_1 = l1_loss(outputs, labels)\n",
    "        loss = l_p + 0.2 * l_1\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'|-Train-|{epoch}: {train_loss:.3f}')\n",
    "        #writer.add_losses(\"Loss\", \"train\",  train_loss, epoch)\n",
    "        #writer.add_losses(\"Loss_l1\", \"train\",  train_loss, epoch)\n",
    "\n",
    "    # Validate the model.\n",
    "    val_loss = 0\n",
    "    val_metric = 0\n",
    "\n",
    "    if 1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_dataloader:\n",
    "                val_inputs = val_inputs.squeeze(0).to(device)\n",
    "                val_labels = val_labels.squeeze(0).to(device)\n",
    "                #val_sub_id = val_sub_id.to(device)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss   += pearson_loss(val_outputs, val_labels).mean()\n",
    "                val_metric += pearson_metric(val_outputs, val_labels).mean()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_metric /= len(val_dataloader)\n",
    "            val_metric = val_metric.mean()\n",
    "\n",
    "            print(f'|-Validation-|{epoch}: {val_loss.mean().item():.3f} {val_metric.item():.3f}')\n",
    "            #writer.add_losses(\"Loss\", \"Validation\",  val_loss, epoch)\n",
    "            #writer.add_losses(\"Pearson\", \"Validation\",  val_metric, epoch)\n",
    "\n",
    "            # Test the model.\n",
    "            test_loss = 0\n",
    "            test_metric = 0\n",
    "\n",
    "            for test_inputs, test_labels in test_dataloader:\n",
    "                test_inputs = test_inputs.squeeze(0).to(device)\n",
    "                test_labels = test_labels.squeeze(0).to(device)\n",
    "                #test_sub_id = test_sub_id.to(device)\n",
    "\n",
    "                test_outputs = model(test_inputs)\n",
    "                test_loss += pearson_loss(test_outputs, test_labels).mean()\n",
    "                test_metric += pearson_metric(test_outputs, test_labels).mean()\n",
    "\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_metric /= len(test_dataloader)\n",
    "            test_metric = test_metric.mean()    \n",
    "            print(f'|-Test-|{epoch}: {test_loss.mean().item():.3f} {test_metric.item():.3f}')\n",
    "            #writer.add_losses(\"Loss\", \"Test\",  test_loss.mean().item(), epoch)\n",
    "            #writer.add_losses(\"Pearson\", \"Test\",  test_metric, epoch)\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         learning_rate = print(optimizer.param_groups[0][\"lr\"])\n",
    "#         save_checkpoint(model, optimizer, learning_rate, epoch, save_path)    \n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cf0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c94814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
