{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33bfba3-f84c-43db-bad5-6ed057b7ab0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e3b275-a3c1-4e3a-a51a-3003d5833390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from random import randint\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch \n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636779",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Establishing folder structure for dataset \n",
    "data_split -> sub -> audio_material -> type_of_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f32d7b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_ext = \"*.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d1bce8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dir_pth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_pth, file_ext))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_pth' is not defined"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(dir_pth, file_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983b4047",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_segmentation(fpath : str):\n",
    "  fname = (fpath.split(\"/\")[-1])\n",
    "  file_seg = (fpath.split(\"/\")[-1]).split(\"_-_\")[0]\n",
    "  print(fname)\n",
    "\n",
    "  # creating sub-dirs : train, val and test\n",
    "  for seg in [\"train\", \"val\", \"test\"]:\n",
    "    sub_dir = os.path.join(dir_pth, seg)\n",
    "    if not os.path.exists(sub_dir):\n",
    "      os.makedirs(sub_dir)\n",
    "\n",
    "  # moving file to desired segment folder\n",
    "  src_file = fpath\n",
    "  dest_file = os.path.join(dir_pth, file_seg, fname)\n",
    "  shutil.move(src_file, dest_file)\n",
    "\n",
    "  # Check if the file has been moved\n",
    "  if os.path.exists(dest_file):\n",
    "    print(f\"File has been moved to : {dest_file}\")\n",
    "  else:\n",
    "    print(\"File move operation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3a66f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m      2\u001b[0m   data_segmentation(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "for f in file_list:\n",
    "  data_segmentation(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a5e8a-f8cc-4335-95b2-6e82d300004a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "261a9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/kunal/eeg_data/derivatives/toy_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d55e5a8-4b6c-416c-b181-b5c1d463b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eeg_file_path = '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_eeg.npy'\n",
    "test_mel_file_path = '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_mel.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d157a7-ecf3-4536-9608-02da2fd756aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.unfold(0, self.frame_length, self.hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1c4406-36ec-415d-a2f4-9dfa859d86c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_eeg.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## test sliding window\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m try_eeg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_eeg_file_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m try_mel\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mload(test_mel_file_path))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEEG: \u001b[39m\u001b[38;5;124m\"\u001b[39m,) \n",
      "File \u001b[0;32m~/WeHear/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/klvijeth/Documents/ML-project/toy_split/test/test_-_sub-001_-_audiobook_1_-_eeg.npy'"
     ]
    }
   ],
   "source": [
    "## test sliding window\n",
    "try_eeg = torch.from_numpy(np.load(test_eeg_file_path))\n",
    "try_mel= torch.from_numpy(np.load(test_mel_file_path))\n",
    "print(\"EEG: \",) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c69902-092b-4827-8817-32138641c48d",
   "metadata": {},
   "source": [
    "### Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bb0061c-795b-4ae2-a9db-dbdd297065d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{1}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a679f02-0e6c-4cd6-843d-ad827a4a7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(data.Dataset):\n",
    "    def __init__(self, files, input_length, channels, task, g_con = True) -> None:\n",
    "        super().__init__()\n",
    "        self.input_length = input_length\n",
    "        self.files = self.group_recordings(files)\n",
    "        self.channels = channels\n",
    "        self.task = task\n",
    "        self.g_con = g_con\n",
    "\n",
    "    def group_recordings(self, files):\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "        return new_files\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, recording_index):\n",
    "        if self.task !=\"test\":\n",
    "            framed_data = []\n",
    "            for idx, feature in enumerate(self.files[recording_index]):\n",
    "                data = np.load(feature)\n",
    "                if idx == 0:\n",
    "                    start_idx = randint(0, len(data) - self.input_length)\n",
    "                    \n",
    "                framed_data += [data[start_idx:start_idx + self.input_length]]\n",
    "            if self.g_con == True:\n",
    "                sub_id = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "                sub_id = int(sub_id) - 1\n",
    "            else:\n",
    "                sub_id = torch.FloatTensor([0])\n",
    "            return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1])\n",
    "        else:\n",
    "            for idx, feature in enumerate(self.files[recording_index]):\n",
    "                data = np.load(feature)\n",
    "                nsegment = data.shape[0] // self.input_length\n",
    "                data = data[:int(nsegment * self.input_length)]\n",
    "                segment_data = [torch.FloatTensor(data[i:i+self.input_length]).unsqueeze(0) for i in range(0, data.shape[0], self.input_length)]\n",
    "                segment_data = torch.cat(segment_data)\n",
    "                framed_data += [segment_data]\n",
    "            \n",
    "            if self.g_con == True:\n",
    "                sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "                sub_idx = int(sub_idx) - 1    \n",
    "    \n",
    "            else:\n",
    "                sub_idx = torch.FloatTensor([0])\n",
    "            return framed_data[0], framed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ede82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5578e769-9706-49de-bdf4-36cb27064b54",
   "metadata": {},
   "source": [
    "### Lightning DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0821087a-694e-4ad4-8aa7-dcbd135c7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(y_true, y_pred, axis=1):\n",
    "\n",
    "    y_true_mean = torch.mean(y_true, dim=axis, keepdim=True)\n",
    "    y_pred_mean = torch.mean(y_pred, dim=axis, keepdim=True)\n",
    "\n",
    "    # Compute the numerator and denominator of the pearson correlation.\n",
    "    numerator = torch.sum((y_true - y_true_mean) * (y_pred - y_pred_mean),\n",
    "        dim=axis,\n",
    "        keepdim=False)\n",
    "\n",
    "    std_true = torch.sum((y_true - y_true_mean)**2, dim=axis, keepdim=False)\n",
    "    std_pred = torch.sum((y_pred - y_pred_mean)**2, dim=axis, keepdim=False)\n",
    "    denominator = torch.sqrt(std_true * std_pred)\n",
    "    \n",
    "    pearsonR = torch.div(numerator, denominator + 1e-6)\n",
    "\n",
    "    assert torch.all(torch.lt(pearsonR, 1)) and torch.all(torch.gt(pearsonR, -1)), \"Loss contains values outside the range of -1 to 1\"\n",
    "\n",
    "    return pearsonR\n",
    "\n",
    "\n",
    "def pearson_loss(y_true, y_pred, axis=1):\n",
    "    return -pearson_correlation(y_true, y_pred, axis=axis)\n",
    "\n",
    "def pearson_metric(y_true, y_pred, axis=1):\n",
    "    return pearson_correlation(y_true, y_pred, axis=axis)\n",
    "    \n",
    "def l1_loss(y_true, y_pred, axis=1):\n",
    "    l1_dist = torch.abs(y_true - y_pred)\n",
    "    l1_loss = torch.mean(l1_dist, axis = axis, keepdim=False)\n",
    "    return l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b86ac5cf-5ec8-4359-b8e6-cb0f9115719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pdb\n",
    "from random import randint\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    \"\"\"Generate data for the regression task.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        files,\n",
    "        input_length,\n",
    "        channels,\n",
    "        task,\n",
    "        g_con = True\n",
    "    ):\n",
    "\n",
    "        self.input_length = input_length\n",
    "        self.files = self.group_recordings(files)\n",
    "        self.channels = channels\n",
    "        self.task = task\n",
    "        self.g_con = g_con\n",
    "\n",
    "    def group_recordings(self, files):\n",
    " \n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3]))\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "\n",
    "        return new_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, recording_index):\n",
    "        \n",
    "        # 1. For within subject, return eeg, envelope and subject ID\n",
    "        # 2. For held-out subject, return eeg, envelope\n",
    "\n",
    "        if self.task == \"train\":\n",
    "            x, y = self.__train_data__(recording_index)\n",
    "\n",
    "        else:\n",
    "            x, y = self.__test_data__(recording_index)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __train_data__(self, recording_index):\n",
    "\n",
    "        framed_data = []\n",
    "\n",
    "        for idx, feature in enumerate(self.files[recording_index]):\n",
    "            data = np.load(feature)\n",
    "\n",
    "            if idx == 0: \n",
    "                start_idx= randint(0,len(data)- self.input_length)\n",
    "\n",
    "            framed_data += [data[start_idx:start_idx + self.input_length]]\n",
    "\n",
    "        if self.g_con == True:\n",
    "            sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "            sub_idx = int(sub_idx) - 1 \n",
    "    \n",
    "        else:\n",
    "            sub_idx = torch.FloatTensor([0])\n",
    "    \n",
    "            # return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1]), sub_idx\n",
    "        \n",
    "            \n",
    "        return torch.FloatTensor(framed_data[0]), torch.FloatTensor(framed_data[1])\n",
    "\n",
    "    def __test_data__(self, recording_index):\n",
    "        \"\"\"\n",
    "        return: list of segments [[eeg, envelope] ...] depending on self.input_length \n",
    "                e.g.,for 10 second-long input signal and input_length==5, return [[5, 5], [5, 5]]\n",
    "        \n",
    "        \"\"\"\n",
    "        framed_data = []\n",
    "\n",
    "        for idx, feature in enumerate(self.files[recording_index]):\n",
    "            data = np.load(feature)\n",
    "            nsegment = data.shape[0] // self.input_length\n",
    "            data = data[:int(nsegment * self.input_length)]\n",
    "            segment_data = [torch.FloatTensor(data[i:i+self.input_length]).unsqueeze(0) for i in range(0, data.shape[0], self.input_length)]\n",
    "            segment_data = torch.cat(segment_data)\n",
    "            framed_data += [segment_data]\n",
    "            \n",
    "        if self.g_con == True:\n",
    "            sub_idx = feature.split('/')[-1].split('_-_')[1].split('-')[-1]\n",
    "            sub_idx = int(sub_idx) - 1    \n",
    "\n",
    "        else:\n",
    "            sub_idx = torch.FloatTensor([0])\n",
    "\n",
    "        return framed_data[0], framed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06c9caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"eeg\"] + [\"mel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4418aa39-2086-4381-bade-2fca02eae335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourModel(\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (conv): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class YourModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "        self.conv = nn.Conv1d(64, 128, kernel_size = 7, padding=3)\n",
    "\n",
    "    def forward(self, dec_input):\n",
    "        dec_output = self.conv(dec_input.transpose(1,2))\n",
    "        dec_output = dec_output.transpose(1,2)\n",
    "        #print(dec_output.size())\n",
    "        dec_output=self.fc(dec_output)\n",
    "        return dec_output\n",
    "\n",
    "# Assuming nb_channels, nb_filters, and integration_window are defined\n",
    "nb_channels = 64\n",
    "nb_filters = 1\n",
    "integration_window = 32\n",
    "\n",
    "# Create an instance of the model\n",
    "model = YourModel().to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3362d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"/home/kunal/eeg_data/derivatives/split_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "602abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=0.0005,\n",
    "                                betas=(0.9, 0.98),\n",
    "                                eps=1e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a43b078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RegressionDataset object at 0x7fd9e777a790>\n"
     ]
    }
   ],
   "source": [
    "train_files = [x for x in glob.glob(os.path.join(folder_path+\"/train/\",\"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "train_set= RegressionDataset(train_files, 640, 64, 'train', False)\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d341f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size = 1,\n",
    "            num_workers = 0,\n",
    "            sampler = None,\n",
    "            drop_last=True,\n",
    "            shuffle=True)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5a1dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = [x for x in glob.glob(os.path.join(folder_path+\"/val/\", \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "val_set = RegressionDataset(val_files, 640, 64, 'val', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d95dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "045a6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size = 1,\n",
    "        num_workers = 0,\n",
    "        sampler = None,\n",
    "        drop_last=True,\n",
    "        shuffle=False)\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3e5adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [x for x in glob.glob(os.path.join(folder_path+\"/test/\", \"test_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "test_set = RegressionDataset(test_files, 640, 64, 'test', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb12617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size = 1,\n",
    "        num_workers = 0,\n",
    "        sampler = None,\n",
    "        drop_last=True,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f753055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "#writer = get_writer(result_folder, experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fee88fb-97ad-4e54-b459-14e840de3be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourModel(\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (conv): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      ")\n",
      "Epoch 1\n",
      "|-Train-|0: 0.121\n",
      "|-Validation-|0: -0.017 0.017\n",
      "|-Test-|0: -0.016 0.016\n",
      "Epoch 2\n",
      "|-Train-|1: 0.117\n",
      "|-Validation-|1: -0.008 0.008\n",
      "|-Test-|1: -0.008 0.008\n",
      "Epoch 3\n",
      "|-Train-|2: 0.124\n",
      "|-Validation-|2: -0.009 0.009\n",
      "|-Test-|2: -0.009 0.009\n",
      "Epoch 4\n",
      "|-Train-|3: 0.124\n",
      "|-Validation-|3: -0.010 0.010\n",
      "|-Test-|3: -0.008 0.008\n",
      "Epoch 5\n",
      "|-Train-|4: 0.120\n",
      "|-Validation-|4: -0.009 0.009\n",
      "|-Test-|4: -0.010 0.010\n",
      "Epoch 6\n",
      "|-Train-|5: 0.121\n",
      "|-Validation-|5: -0.015 0.015\n",
      "|-Test-|5: -0.014 0.014\n",
      "Epoch 7\n",
      "|-Train-|6: 0.122\n",
      "|-Validation-|6: -0.011 0.011\n",
      "|-Test-|6: -0.009 0.009\n",
      "Epoch 8\n",
      "|-Train-|7: 0.123\n",
      "|-Validation-|7: -0.014 0.014\n",
      "|-Test-|7: -0.014 0.014\n",
      "Epoch 9\n",
      "|-Train-|8: 0.118\n",
      "|-Validation-|8: -0.014 0.014\n",
      "|-Test-|8: -0.013 0.013\n",
      "Epoch 10\n",
      "|-Train-|9: 0.121\n",
      "|-Validation-|9: -0.013 0.013\n",
      "|-Test-|9: -0.013 0.013\n",
      "Epoch 11\n",
      "|-Train-|10: 0.117\n",
      "|-Validation-|10: -0.014 0.014\n",
      "|-Test-|10: -0.014 0.014\n",
      "Epoch 12\n",
      "|-Train-|11: 0.120\n",
      "|-Validation-|11: -0.011 0.011\n",
      "|-Test-|11: -0.009 0.009\n",
      "Epoch 13\n",
      "|-Train-|12: 0.119\n",
      "|-Validation-|12: -0.012 0.012\n",
      "|-Test-|12: -0.013 0.013\n",
      "Epoch 14\n",
      "|-Train-|13: 0.123\n",
      "|-Validation-|13: -0.011 0.011\n",
      "|-Test-|13: -0.009 0.009\n",
      "Epoch 15\n",
      "|-Train-|14: 0.117\n",
      "|-Validation-|14: -0.014 0.014\n",
      "|-Test-|14: -0.013 0.013\n",
      "Epoch 16\n",
      "|-Train-|15: 0.121\n",
      "|-Validation-|15: -0.011 0.011\n",
      "|-Test-|15: -0.011 0.011\n",
      "Epoch 17\n",
      "|-Train-|16: 0.120\n",
      "|-Validation-|16: -0.013 0.013\n",
      "|-Test-|16: -0.012 0.012\n",
      "Epoch 18\n",
      "|-Train-|17: 0.119\n",
      "|-Validation-|17: -0.005 0.005\n",
      "|-Test-|17: -0.006 0.006\n",
      "Epoch 19\n",
      "|-Train-|18: 0.122\n",
      "|-Validation-|18: -0.015 0.015\n",
      "|-Test-|18: -0.015 0.015\n",
      "Epoch 20\n",
      "|-Train-|19: 0.120\n",
      "|-Validation-|19: -0.018 0.018\n",
      "|-Test-|19: -0.017 0.017\n",
      "Epoch 21\n",
      "|-Train-|20: 0.118\n",
      "|-Validation-|20: -0.011 0.011\n",
      "|-Test-|20: -0.011 0.011\n",
      "Epoch 22\n",
      "|-Train-|21: 0.121\n",
      "|-Validation-|21: -0.014 0.014\n",
      "|-Test-|21: -0.013 0.013\n",
      "Epoch 23\n",
      "|-Train-|22: 0.118\n",
      "|-Validation-|22: -0.008 0.008\n",
      "|-Test-|22: -0.008 0.008\n",
      "Epoch 24\n",
      "|-Train-|23: 0.121\n",
      "|-Validation-|23: -0.016 0.016\n",
      "|-Test-|23: -0.014 0.014\n",
      "Epoch 25\n",
      "|-Train-|24: 0.117\n",
      "|-Validation-|24: -0.014 0.014\n",
      "|-Test-|24: -0.013 0.013\n",
      "Epoch 26\n",
      "|-Train-|25: 0.117\n",
      "|-Validation-|25: -0.011 0.011\n",
      "|-Test-|25: -0.010 0.010\n",
      "Epoch 27\n",
      "|-Train-|26: 0.121\n",
      "|-Validation-|26: -0.014 0.014\n",
      "|-Test-|26: -0.013 0.013\n",
      "Epoch 28\n",
      "|-Train-|27: 0.124\n",
      "|-Validation-|27: -0.014 0.014\n",
      "|-Test-|27: -0.014 0.014\n",
      "Epoch 29\n",
      "|-Train-|28: 0.123\n",
      "|-Validation-|28: -0.011 0.011\n",
      "|-Test-|28: -0.012 0.012\n",
      "Epoch 30\n",
      "|-Train-|29: 0.122\n",
      "|-Validation-|29: -0.010 0.010\n",
      "|-Test-|29: -0.010 0.010\n",
      "Epoch 31\n",
      "|-Train-|30: 0.118\n",
      "|-Validation-|30: -0.008 0.008\n",
      "|-Test-|30: -0.009 0.009\n",
      "Epoch 32\n",
      "|-Train-|31: 0.116\n",
      "|-Validation-|31: -0.016 0.016\n",
      "|-Test-|31: -0.016 0.016\n",
      "Epoch 33\n",
      "|-Train-|32: 0.114\n",
      "|-Validation-|32: -0.015 0.015\n",
      "|-Test-|32: -0.013 0.013\n",
      "Epoch 34\n",
      "|-Train-|33: 0.121\n",
      "|-Validation-|33: -0.005 0.005\n",
      "|-Test-|33: -0.006 0.006\n",
      "Epoch 35\n",
      "|-Train-|34: 0.115\n",
      "|-Validation-|34: -0.007 0.007\n",
      "|-Test-|34: -0.007 0.007\n",
      "Epoch 36\n",
      "|-Train-|35: 0.113\n",
      "|-Validation-|35: -0.012 0.012\n",
      "|-Test-|35: -0.010 0.010\n",
      "Epoch 37\n",
      "|-Train-|36: 0.119\n",
      "|-Validation-|36: -0.011 0.011\n",
      "|-Test-|36: -0.010 0.010\n",
      "Epoch 38\n",
      "|-Train-|37: 0.121\n",
      "|-Validation-|37: -0.018 0.018\n",
      "|-Test-|37: -0.016 0.016\n",
      "Epoch 39\n",
      "|-Train-|38: 0.119\n",
      "|-Validation-|38: -0.011 0.011\n",
      "|-Test-|38: -0.011 0.011\n",
      "Epoch 40\n",
      "|-Train-|39: 0.118\n",
      "|-Validation-|39: -0.010 0.010\n",
      "|-Test-|39: -0.010 0.010\n",
      "Epoch 41\n",
      "|-Train-|40: 0.115\n",
      "|-Validation-|40: -0.014 0.014\n",
      "|-Test-|40: -0.011 0.011\n",
      "Epoch 42\n",
      "|-Train-|41: 0.113\n",
      "|-Validation-|41: -0.011 0.011\n",
      "|-Test-|41: -0.011 0.011\n",
      "Epoch 43\n",
      "|-Train-|42: 0.123\n",
      "|-Validation-|42: -0.011 0.011\n",
      "|-Test-|42: -0.010 0.010\n",
      "Epoch 44\n",
      "|-Train-|43: 0.112\n",
      "|-Validation-|43: -0.012 0.012\n",
      "|-Test-|43: -0.013 0.013\n",
      "Epoch 45\n",
      "|-Train-|44: 0.118\n",
      "|-Validation-|44: -0.008 0.008\n",
      "|-Test-|44: -0.006 0.006\n",
      "Epoch 46\n",
      "|-Train-|45: 0.116\n",
      "|-Validation-|45: -0.013 0.013\n",
      "|-Test-|45: -0.013 0.013\n",
      "Epoch 47\n",
      "|-Train-|46: 0.117\n",
      "|-Validation-|46: -0.016 0.016\n",
      "|-Test-|46: -0.016 0.016\n",
      "Epoch 48\n",
      "|-Train-|47: 0.115\n",
      "|-Validation-|47: -0.016 0.016\n",
      "|-Test-|47: -0.015 0.015\n",
      "Epoch 49\n",
      "|-Train-|48: 0.116\n",
      "|-Validation-|48: -0.013 0.013\n",
      "|-Test-|48: -0.013 0.013\n",
      "Epoch 50\n",
      "|-Train-|49: 0.120\n",
      "|-Validation-|49: -0.014 0.014\n",
      "|-Test-|49: -0.013 0.013\n",
      "Epoch 51\n",
      "|-Train-|50: 0.118\n",
      "|-Validation-|50: -0.015 0.015\n",
      "|-Test-|50: -0.014 0.014\n",
      "Epoch 52\n",
      "|-Train-|51: 0.114\n",
      "|-Validation-|51: -0.013 0.013\n",
      "|-Test-|51: -0.013 0.013\n",
      "Epoch 53\n",
      "|-Train-|52: 0.116\n",
      "|-Validation-|52: -0.015 0.015\n",
      "|-Test-|52: -0.014 0.014\n",
      "Epoch 54\n",
      "|-Train-|53: 0.116\n",
      "|-Validation-|53: -0.018 0.018\n",
      "|-Test-|53: -0.017 0.017\n",
      "Epoch 55\n",
      "|-Train-|54: 0.116\n",
      "|-Validation-|54: -0.016 0.016\n",
      "|-Test-|54: -0.015 0.015\n",
      "Epoch 56\n",
      "|-Train-|55: 0.116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_inputs, val_labels \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[1;32m     40\u001b[0m         val_inputs \u001b[38;5;241m=\u001b[39m val_inputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m         val_labels \u001b[38;5;241m=\u001b[39m val_labels\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/WeHear/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/WeHear/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/WeHear/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/WeHear/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[38], line 48\u001b[0m, in \u001b[0;36mRegressionDataset.__getitem__\u001b[0;34m(self, recording_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__train_data__(recording_index)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__test_data__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "Cell \u001b[0;32mIn[38], line 89\u001b[0m, in \u001b[0;36mRegressionDataset.__test_data__\u001b[0;34m(self, recording_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m nsegment \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length\n\u001b[1;32m     88\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;28mint\u001b[39m(nsegment \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length)]\n\u001b[0;32m---> 89\u001b[0m segment_data \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mFloatTensor(data[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length)]\n\u001b[1;32m     90\u001b[0m segment_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(segment_data)\n\u001b[1;32m     91\u001b[0m framed_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [segment_data]\n",
      "Cell \u001b[0;32mIn[38], line 89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m nsegment \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length\n\u001b[1;32m     88\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;28mint\u001b[39m(nsegment \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length)]\n\u001b[0;32m---> 89\u001b[0m segment_data \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_length\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length)]\n\u001b[1;32m     90\u001b[0m segment_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(segment_data)\n\u001b[1;32m     91\u001b[0m framed_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [segment_data]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch\",epoch+1)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #sub_id = sub_id.to(device)\n",
    "        outputs = model(inputs).to(device)\n",
    "\n",
    "        l_p = pearson_loss(outputs, labels) \n",
    "        l_1 = l1_loss(outputs, labels)\n",
    "        loss = l_p + 0.2 * l_1\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'|-Train-|{epoch}: {train_loss:.3f}')\n",
    "        #writer.add_losses(\"Loss\", \"train\",  train_loss, epoch)\n",
    "        #writer.add_losses(\"Loss_l1\", \"train\",  train_loss, epoch)\n",
    "\n",
    "    # Validate the model.\n",
    "    val_loss = 0\n",
    "    val_metric = 0\n",
    "\n",
    "    if 1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_dataloader:\n",
    "                val_inputs = val_inputs.squeeze(0).to(device)\n",
    "                val_labels = val_labels.squeeze(0).to(device)\n",
    "                #val_sub_id = val_sub_id.to(device)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss   += pearson_loss(val_outputs, val_labels).mean()\n",
    "                val_metric += pearson_metric(val_outputs, val_labels).mean()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_metric /= len(val_dataloader)\n",
    "            val_metric = val_metric.mean()\n",
    "\n",
    "            print(f'|-Validation-|{epoch}: {val_loss.mean().item():.3f} {val_metric.item():.3f}')\n",
    "            #writer.add_losses(\"Loss\", \"Validation\",  val_loss, epoch)\n",
    "            #writer.add_losses(\"Pearson\", \"Validation\",  val_metric, epoch)\n",
    "\n",
    "            # Test the model.\n",
    "            test_loss = 0\n",
    "            test_metric = 0\n",
    "\n",
    "            for test_inputs, test_labels in test_dataloader:\n",
    "                test_inputs = test_inputs.squeeze(0).to(device)\n",
    "                test_labels = test_labels.squeeze(0).to(device)\n",
    "                #test_sub_id = test_sub_id.to(device)\n",
    "\n",
    "                test_outputs = model(test_inputs)\n",
    "                test_loss += pearson_loss(test_outputs, test_labels).mean()\n",
    "                test_metric += pearson_metric(test_outputs, test_labels).mean()\n",
    "\n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_metric /= len(test_dataloader)\n",
    "            test_metric = test_metric.mean()    \n",
    "            print(f'|-Test-|{epoch}: {test_loss.mean().item():.3f} {test_metric.item():.3f}')\n",
    "            #writer.add_losses(\"Loss\", \"Test\",  test_loss.mean().item(), epoch)\n",
    "            #writer.add_losses(\"Pearson\", \"Test\",  test_metric, epoch)\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         learning_rate = print(optimizer.param_groups[0][\"lr\"])\n",
    "#         save_checkpoint(model, optimizer, learning_rate, epoch, save_path)    \n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cf0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c94814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
